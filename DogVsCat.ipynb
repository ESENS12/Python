{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Conv2D, Flatten, Dropout, MaxPooling2D\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "_URL = 'https://storage.googleapis.com/mledu-datasets/cats_and_dogs_filtered.zip'\n",
    "\n",
    "path_to_zip = tf.keras.utils.get_file('cats_and_dogs.zip', origin=_URL, extract=True)\n",
    "\n",
    "PATH = os.path.join(os.path.dirname(path_to_zip), 'cats_and_dogs_filtered')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dir = os.path.join(PATH, 'train')\n",
    "validation_dir = os.path.join(PATH, 'validation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_cats_dir = os.path.join(train_dir, 'cats')  # directory with our training cat pictures\n",
    "train_dogs_dir = os.path.join(train_dir, 'dogs')  # directory with our training dog pictures\n",
    "validation_cats_dir = os.path.join(validation_dir, 'cats')  # directory with our validation cat pictures\n",
    "validation_dogs_dir = os.path.join(validation_dir, 'dogs')  # directory with our validation dog pictures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_cats_tr = len(os.listdir(train_cats_dir))\n",
    "num_dogs_tr = len(os.listdir(train_dogs_dir))\n",
    "\n",
    "num_cats_val = len(os.listdir(validation_cats_dir))\n",
    "num_dogs_val = len(os.listdir(validation_dogs_dir))\n",
    "\n",
    "total_train = num_cats_tr + num_dogs_tr\n",
    "total_val = num_cats_val + num_dogs_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total training cat images: 1000\n",
      "total training dog images: 1000\n",
      "train_cats_dir :  /Users/esens/.keras/datasets/cats_and_dogs_filtered/train/cats\n",
      "total validation cat images: 500\n",
      "total validation dog images: 500\n",
      "--\n",
      "Total training images: 2000\n",
      "Total validation images: 1000\n"
     ]
    }
   ],
   "source": [
    "print('total training cat images:', num_cats_tr)\n",
    "print('total training dog images:', num_dogs_tr)\n",
    "print('train_cats_dir : ' , train_cats_dir);\n",
    "\n",
    "print('total validation cat images:', num_cats_val)\n",
    "print('total validation dog images:', num_dogs_val)\n",
    "print(\"--\")\n",
    "print(\"Total training images:\", total_train)\n",
    "print(\"Total validation images:\", total_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "epochs = 15\n",
    "IMG_HEIGHT = 150\n",
    "IMG_WIDTH = 150"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2000 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "#for training data \n",
    "train_image_generator = ImageDataGenerator(rescale=1./255) # Generator for our training data\n",
    "train_data_gen = train_image_generator.flow_from_directory(batch_size=batch_size,\n",
    "                                                           directory=train_dir,\n",
    "                                                           shuffle=True,\n",
    "                                                           target_size=(IMG_HEIGHT, IMG_WIDTH),\n",
    "                                                           class_mode='binary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1000 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "#for validation data \n",
    "validation_image_generator = ImageDataGenerator(rescale=1./255) # Generator for our validation data\n",
    "val_data_gen = validation_image_generator.flow_from_directory(batch_size=batch_size,\n",
    "                                                              directory=validation_dir,\n",
    "                                                              target_size=(IMG_HEIGHT, IMG_WIDTH),\n",
    "                                                              class_mode='binary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_training_images, _ = next(train_data_gen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotImages(images_arr):\n",
    "    fig, axes = plt.subplots(1, 5, figsize=(20,20))\n",
    "    axes = axes.flatten()\n",
    "    for img, ax in zip( images_arr, axes):\n",
    "        ax.imshow(img)\n",
    "        ax.axis('off')\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotImages(sample_training_images[:5])\n",
    "# create the model\n",
    "def create_model():\n",
    "    model = Sequential([\n",
    "        Conv2D(16, 3, padding='same', activation='relu', input_shape=(IMG_HEIGHT, IMG_WIDTH ,3)),\n",
    "        MaxPooling2D(),\n",
    "        Conv2D(32, 3, padding='same', activation='relu'),\n",
    "        MaxPooling2D(),\n",
    "        Conv2D(64, 3, padding='same', activation='relu'),\n",
    "        MaxPooling2D(),\n",
    "        Flatten(),\n",
    "        Dense(512, activation='relu'),\n",
    "        Dense(1)\n",
    "    ])\n",
    "    model.compile(optimizer='adam',\n",
    "              loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 150, 150, 16)      448       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 75, 75, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 75, 75, 32)        4640      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 37, 37, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 37, 37, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 18, 18, 64)        0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 20736)             0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 512)               10617344  \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 513       \n",
      "=================================================================\n",
      "Total params: 10,641,441\n",
      "Trainable params: 10,641,441\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = create_model();\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of samples seen.\n"
     ]
    }
   ],
   "source": [
    "# 모델 저장\n",
    "checkpoint_path = \"trained_dogcat_0513/cp-{epoch:04d}.ckpt\"\n",
    "checkpoint_dir = os.path.dirname(checkpoint_path)\n",
    "\n",
    "cp_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "    checkpoint_path, verbose=1, save_weights_only=True,\n",
    "    # 15번째 에포크에서 저장\n",
    "    period=15)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'trained_dogcat_0513/cp-{epoch:04d}.ckpt'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checkpoint_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train model\n",
    "\n",
    "# history = model.fit_generator(\n",
    "#     train_data_gen,\n",
    "#     steps_per_epoch=total_train // batch_size,\n",
    "#     epochs=epochs,\n",
    "#     callbacks =[cp_callback],\n",
    "#     validation_data=val_data_gen,\n",
    "#     validation_steps=total_val // batch_size\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "checkpoint                       cp-0015.ckpt.index\r\n",
      "cp-0015.ckpt.data-00000-of-00001\r\n"
     ]
    }
   ],
   "source": [
    "! ls {checkpoint_dir}\n",
    "# acc = history.history['accuracy']\n",
    "# val_acc = history.history['val_accuracy']\n",
    "\n",
    "# loss=history.history['loss']\n",
    "# val_loss=history.history['val_loss']\n",
    "\n",
    "# epochs_range = range(epochs)\n",
    "\n",
    "# plt.figure(figsize=(8, 8))\n",
    "# plt.subplot(1, 2, 1)\n",
    "# plt.plot(epochs_range, acc, label='Training Accuracy')\n",
    "# plt.plot(epochs_range, val_acc, label='Validation Accuracy')\n",
    "# plt.legend(loc='lower right')\n",
    "# plt.title('Training and Validation Accuracy')\n",
    "\n",
    "# plt.subplot(1, 2, 2)\n",
    "# plt.plot(epochs_range, loss, label='Training Loss')\n",
    "# plt.plot(epochs_range, val_loss, label='Validation Loss')\n",
    "# plt.legend(loc='upper right')\n",
    "# plt.title('Training and Validation Loss')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 4 images belonging to 3 classes.\n",
      "test_data_gen :  <keras_preprocessing.image.directory_iterator.DirectoryIterator object at 0x1738dbeb8>\n"
     ]
    }
   ],
   "source": [
    "PATH =\"/Users/esens/Python/my_test_image/\"\n",
    "\n",
    "test_image_generator = tf.keras.preprocessing.image.ImageDataGenerator(rescale=1./255)\n",
    "test_data_gen = test_image_generator.flow_from_directory(directory=str(PATH),\n",
    "                                                batch_size=batch_size,\n",
    "                                                target_size=(IMG_HEIGHT, IMG_WIDTH),\n",
    "                                                class_mode='binary')\n",
    "print(\"test_data_gen : \" , test_data_gen)\n",
    "print(test_data_gen.labels)\n",
    "#data_dir = tf.keras.utils.get_file(origin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trained_dogcat_0513/cp-0015.ckpt\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x161d1d710>"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load last checkpoint\n",
    "latest = tf.train.latest_checkpoint(checkpoint_dir)\n",
    "print(latest)\n",
    "\n",
    "# create model\n",
    "model = create_model()\n",
    "model.load_weights(latest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========pridiction========\n",
      "{'cat': 0, 'dog': 1, 'tiger': 2}\n",
      "predictions class :  [[1]]\n"
     ]
    }
   ],
   "source": [
    "my_img_path = \"/Users/esens/Python/my_test_image/dog/dog01.jpeg\"\n",
    "image = tf.keras.preprocessing.image.load_img(my_img_path,target_size=(150, 150))\n",
    "\n",
    "input_arr = keras.preprocessing.image.img_to_array(image)\n",
    "input_arr = np.array([input_arr])  # Convert single image to a batch.\n",
    "\n",
    "#print(\"model shape : \" , model.summary());\n",
    "# print(\"input_arr : \", input_arr)\n",
    "\n",
    "predictions_class = model.predict_classes(input_arr)\n",
    "predictions = model.predict(input_arr)\n",
    "\n",
    "print(\"========pridiction========\")\n",
    "print(test_data_gen.class_indices)\n",
    "print(\"predictions class : \" , predictions_class);\n",
    "#print(\"predictions argmax : \",np.argmax(predictions[0])); # same way\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_value_array(i, predictions_array, true_label):\n",
    "  predictions_array, true_label = predictions_array[i], true_label[i]\n",
    "  plt.grid(False)\n",
    "  plt.xticks([])\n",
    "  plt.yticks([])\n",
    "  thisplot = plt.bar(range(10), predictions_array, color=\"#777777\")\n",
    "  plt.ylim([0, 1])\n",
    "  predicted_label = np.argmax(predictions_array)\n",
    "\n",
    "  thisplot[predicted_label].set_color('red')\n",
    "  thisplot[true_label].set_color('blue')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
