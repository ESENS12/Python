{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib\n",
    "from PIL import Image\n",
    "from io import BytesIO\n",
    "import tensorflow as tf\n",
    "import urllib.request\n",
    "\n",
    "import os\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Conv2D, Flatten, Dropout, MaxPooling2D\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "import urllib\n",
    "import struct\n",
    "import numpy as np\n",
    "import requests\n",
    "\n",
    "from numpy import asarray\n",
    "from array import array\n",
    "import pandas as pd\n",
    "\n",
    "#define const value\n",
    "batch_size = 3000\n",
    "epochs = 15\n",
    "IMG_HEIGHT = 260\n",
    "IMG_WIDTH = 460\n",
    "#IMG_URL = \"https://www.revu.net/campaign/img.php?p=82850a145eceea021405b444cca3b25c0fec1aec23a3b6766de5f1b9b8c50185&v=4\"\n",
    "IMG_URL = \"https://mblogthumb-phinf.pstatic.net/MjAyMDAzMjhfMzQg/MDAxNTg1MzY0NjcyNjY3.3kfk4WR3MhB-phe8wpVGPt4Bwahv_f9rdCeTTj0aPdcg.8Ttg7OOMtwDHRi7pUz8ZSQWcSMPbqlNb7sPmiPYa0aIg.GIF.p_radn/KakaoTalk_20200328_112418316_01.gif?type=w800\"\n",
    "#IMG_URL = \"https://mblogthumb-phinf.pstatic.net/MjAyMDA2MjZfMTcg/MDAxNTkzMTQ5NDg3MzQ0.cbRzmTi6r77_p6sWpmBj753HrR6VbzI4WCwkYMkLFn8g.qCEDdrC6-bblRFrGVDqqmk8fpJlsVJ5WcVyJd59OxBMg.JPEG.limmmm22/SE-631feb29-32d5-4d6b-94c3-9a203b318af3.jpg?type=w800\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model():\n",
    "    model = Sequential([\n",
    "        Conv2D(16, 3, padding='same', activation='relu', input_shape=(IMG_HEIGHT, IMG_WIDTH ,3)),\n",
    "        MaxPooling2D(),\n",
    "        Conv2D(32, 3, padding='same', activation='relu'),\n",
    "        MaxPooling2D(),\n",
    "        Conv2D(64, 3, padding='same', activation='relu'),\n",
    "        MaxPooling2D(),\n",
    "        Flatten(),\n",
    "        Dense(512, activation='relu'),\n",
    "        Dense(1)\n",
    "    ])\n",
    "    model.compile(optimizer='adam',\n",
    "              loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model_diff_width_0624_v1(batch-3000)/cp-0015.ckpt\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x7ffce0412908>"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#load model\n",
    "checkpoint_path = \"model_diff_width_0624_v1(batch-3000)/cp-0015.ckpt\"\n",
    "checkpoint_dir = os.path.dirname(checkpoint_path)\n",
    "\n",
    "latest = tf.train.latest_checkpoint(checkpoint_dir)\n",
    "print(latest)\n",
    "\n",
    "# create model\n",
    "model = create_model()\n",
    "model.load_weights(latest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convertToJpeg(im):\n",
    "    with BytesIO() as f:\n",
    "        new_img = im.convert(\"RGB\")\n",
    "        new_img.save(f, format='JPEG')\n",
    "        return f.getvalue()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_img_to_npArr(uri):\n",
    "    response = urllib.request.urlopen(uri).read()\n",
    "#     print(type(response))\n",
    "#     print(\"response : \",response)\n",
    "#     response = requests.get(uri)\n",
    "    \n",
    "    img = Image.open(BytesIO(response))\n",
    "    print(img.format)\n",
    "    if(img.format == \"PNG\") or (img.format == \"GIF\"):\n",
    "        print(\"this image is \",img.format,\"type. could be change to jpg\")\n",
    "        png_to_jpg = convertToJpeg(img)\n",
    "        img = Image.open(BytesIO(png_to_jpg))\n",
    "#         img.show()\n",
    "\n",
    "    resize_img = img.resize((IMG_WIDTH, IMG_HEIGHT))\n",
    "\n",
    "    input_arr = tf.keras.preprocessing.image.img_to_array(resize_img)\n",
    "    input_arr = np.array([input_arr])  # Convert single image to a batch.\n",
    "\n",
    "    # todo png -> tensor convert\n",
    "    print('shape : ' , input_arr.shape)\n",
    "    \n",
    "    return input_arr\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GIF\n",
      "this image is  GIF type. could be change\n",
      "shape :  (1, 260, 460, 3)\n",
      "========pridiction========\n",
      "predictions class :  [[1]]\n",
      "predictions :  [[854.22534]]\n"
     ]
    }
   ],
   "source": [
    "nparr = conv_img_to_npArr(IMG_URL)\n",
    "predictions_class = model.predict_classes(nparr)\n",
    "predictions = model.predict(nparr)\n",
    "\n",
    "print(\"========pridiction========\");\n",
    "#     print(test_data_gen.class_indices)\n",
    "print(\"predictions class : \" , predictions_class);\n",
    "print(\"predictions : \" , predictions);"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
