{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "from pprint import pprint\n",
    "import requests\n",
    "import urllib.request\n",
    "import os\n",
    "import urllib.parse\n",
    "import shutil\n",
    "#import cv2\n",
    "from PIL import Image\n",
    "\n",
    "import tensorflow.keras\n",
    "from PIL import Image, ImageOps\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "fakeBlogKeywordList = [\"스토리앤\",\"seoulouba\",\"mateb.kr\",\"revu\",\"weble\",\"ohmyblog\",\"mrblog\",\"tble\",\n",
    "    \"dinnerqueen\",\"%EA%B3%B5%EC%A0%95%EA%B1%B0%EB%9E%98%EC%9C%84%EC%9B%90%ED%9A%8C-%EB%AC%B8%EA%B5%AC\",\n",
    "    \"%EB%B8%94%EB%A1%9C%EA%B7%B8%EC%9B%90%EC%A0%95%EB%8C%80\",\n",
    "    \"banner_\",\"%EC%9D%B4%EC%8A%88%EB%B8%94%EB%A1%9C%EA%B7%B8\",\n",
    "    \"%EB%B0%B0%EB%84%88\",\"http://echoblog.net/images/sponsor-banner.png\",\n",
    "                      \"sponsor\",\"banner\",\"echoblog\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Conv2D, Flatten, Dropout, MaxPooling2D\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#define const value\n",
    "batch_size = 3000\n",
    "epochs = 15\n",
    "IMG_HEIGHT = 260\n",
    "IMG_WIDTH = 460\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model():\n",
    "    model = Sequential([\n",
    "        Conv2D(16, 3, padding='same', activation='relu', input_shape=(IMG_HEIGHT, IMG_WIDTH ,3)),\n",
    "        MaxPooling2D(),\n",
    "        Conv2D(32, 3, padding='same', activation='relu'),\n",
    "        MaxPooling2D(),\n",
    "        Conv2D(64, 3, padding='same', activation='relu'),\n",
    "        MaxPooling2D(),\n",
    "        Flatten(),\n",
    "        Dense(512, activation='relu'),\n",
    "        Dense(1)\n",
    "    ])\n",
    "    model.compile(optimizer='adam',\n",
    "              loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model_diff_width_0624_v1(batch-3000)/cp-0015.ckpt\n",
      "WARNING:tensorflow:No training configuration found in save file: the model was *not* compiled. Compile it manually.\n"
     ]
    }
   ],
   "source": [
    "#load model\n",
    "checkpoint_path = \"model_diff_width_0624_v1(batch-3000)/cp-0015.ckpt\"\n",
    "checkpoint_dir = os.path.dirname(checkpoint_path)\n",
    "\n",
    "latest = tf.train.latest_checkpoint(checkpoint_dir)\n",
    "print(latest)\n",
    "\n",
    "# create model\n",
    "model = create_model()\n",
    "model.load_weights(latest)\n",
    "\n",
    "data = np.ndarray(shape=(1, 224, 224, 3), dtype=np.float32)\n",
    "teachable_model = tensorflow.keras.models.load_model('/Users/esens/Downloads/converted_keras/keras_model.h5')\n",
    "np.set_printoptions(suppress=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# =====================================================================\n",
    "#이미지 분류 [teachable machine model]\n",
    "def teachableMachinePrediction(image_path):\n",
    "    try:\n",
    "        image = Image.open(image_path)\n",
    "        size = (224, 224)\n",
    "        image = ImageOps.fit(image, size, Image.ANTIALIAS)\n",
    "        resize = Image.open(image_path);\n",
    "        print(\"image size : \",resize.size);\n",
    "        \n",
    "        image_array = np.asarray(image)\n",
    "        normalized_image_array = (image_array.astype(np.float32) / 127.0) - 1\n",
    "        newdata = np.ndarray(shape=(1, 224, 224, 3), dtype=np.float32)    \n",
    "        \n",
    "#         data = np.array([np.array(cv2.imread(image_path[i])) for i in range(len(image_path))])\n",
    "#         features = data.flatten().reshape(1, 224,224,3)\n",
    "#         print(\"features : \" , features.shape)\n",
    "\n",
    "        if(normalized_image_array.shape == (224,224,4)):\n",
    "            print('224,224,4 : ' , image_path)\n",
    "            print(normalized_image_array.shape)\n",
    "            normalized_image_array_reshape = normalized_image_array.reshape(224,224,3)\n",
    "            print(normalized_image_array_reshape.shape)\n",
    "\n",
    "        elif (normalized_image_array.shape == (224, 224)):\n",
    "            print('224,224 : ', image_path)\n",
    "            normalized_image_array_reshape = normalized_image_array.reshape(-1,224,224,3)\n",
    "            print(normalized_image_array_reshape.shape)\n",
    "\n",
    "        else:\n",
    "            normalized_image_array_reshape = normalized_image_array.reshape(1,224,224,3)\n",
    "\n",
    "        # Load the image into the array\n",
    "        newdata[0] = normalized_image_array_reshape\n",
    "        #todo image shape 다른경우 처리해줘야함(png일 때 로 추측됨..)\n",
    "        print('newdata.shape : ' , newdata.shape)\n",
    "  \n",
    "        #predictions class \n",
    "        # {0 : advertise , 1: others}\n",
    "        \n",
    "        prediction = teachable_model.predict(newdata)\n",
    "        prediction_class = teachable_model.predict_classes(newdata)\n",
    "        #print(\"========pridiction[teachable]========\")\n",
    "        #print(prediction_class)\n",
    "    except Exception as ex:\n",
    "        print(\"predict error[teachable machine] : \" , ex)\n",
    "        \n",
    "    return prediction_class\n",
    "\n",
    "    \n",
    "# =====================================================================\n",
    "#이미지 분류 [my model]\n",
    "\n",
    "def imageClassification(image_path):\n",
    "    image = tf.keras.preprocessing.image.load_img(image_path,target_size=(IMG_HEIGHT, IMG_WIDTH))\n",
    "    input_arr = tf.keras.preprocessing.image.img_to_array(image)\n",
    "    print(\"input_arr type : \" ,type(input_arr))\n",
    "    input_arr = np.array([input_arr])  # Convert single image to a batch.\n",
    "\n",
    "    predictions_class = model.predict_classes(input_arr)\n",
    "    predictions = model.predict(input_arr)\n",
    "\n",
    "    print(\"========pridiction========\");\n",
    "#     print(test_data_gen.class_indices)\n",
    "    print(\"predictions class : \" , predictions_class);\n",
    "    print(\"predictions : \" , predictions);\n",
    "#    print(\"predictions argmax : \",np.argmax(predictions[0])); # same way\n",
    "    return predictions_class;\n",
    "\n",
    "# =====================================================================\n",
    "#이미지 저장\n",
    "def saveImage(div_option,index,img_url,nickName,postNumber):\n",
    "    #블로그 유저 별로 폴더를 나눌건지에 대한 옵션\n",
    "    #true -> path : image/{nickName}/{postNumber}\n",
    "    #false -> path : image/myimg/\n",
    "    if(div_option):\n",
    "        if nickName is \"\":\n",
    "            nickName = \"unknown\"\n",
    "        if postNumber is \"\":\n",
    "            postNumber = \"1\"        \n",
    "        imgPath = f'image/{nickName}/{postNumber}/{index}.jpg'\n",
    "        dirPath = f'image/{nickName}/{postNumber}'\n",
    "    #폴더별로 분기하지 않을떄 path : image/myimg/\n",
    "    else:\n",
    "        list = os.listdir(\"image/temp\")\n",
    "        last_index = len(list)\n",
    "#         print(\"last_index : \",last_index)\n",
    "        dirPath = 'image/temp'\n",
    "        imgPath = f'image/temp/{last_index}.jpg'\n",
    "    \n",
    "    if not os.path.isdir(dirPath):\n",
    "        #폴더 생성\n",
    "        try:\n",
    "            os.makedirs(dirPath)\n",
    "        except Exception as ex:\n",
    "            print(\"error catch : \" , ex)\n",
    "                \n",
    "    #파일 저장\n",
    "    #temp에 저장 -> classification -> 분류 저장\n",
    "    \n",
    "    try:\n",
    "        filename = img_url.split('/')[-1].split('?')[0];\n",
    "        img_url2 = urllib.parse.quote_plus(str(filename))\n",
    "        img_url_final = img_url.replace(img_url.split('/')[-1].split('?')[0],img_url2)\n",
    "        print(\"img_url_final : \" ,img_url_final);\n",
    "        for item in fakeBlogKeywordList:\n",
    "            if(img_url_final.find(item) > 0):\n",
    "                print('this is fake img')\n",
    "\n",
    "                imgPath = f\"image/temp/fake_{last_index}.jpg\"\n",
    "                break;\n",
    "        \n",
    "        urllib.request.urlretrieve(img_url_final, imgPath)\n",
    "        #분류\n",
    "        #{'advertise': 0, 'image': 1}\n",
    "        my_prediction  = imageClassification(imgPath);\n",
    "        #my_prediction  = teachableMachinePrediction(imgPath);\n",
    "#         print(\"prediction : \", my_prediction[0]);\n",
    "        \n",
    "        if (my_prediction[0] == 0):\n",
    "            list = os.listdir(\"ad_img\")\n",
    "            last_index = len(list)\n",
    "            #os.rename(imgPath, f'ad_img/{last_index}.jpg')\n",
    "            #shutil.move(imgPath, f'ad_img/{last_index}.jpg')\n",
    "            os.replace(imgPath, f'ad_img/{last_index}.jpg')\n",
    "            return False\n",
    "        return True\n",
    "    except Exception as ex:\n",
    "        print(\"img save error : \" , ex)\n",
    "        return False\n",
    "    \n",
    "    \n",
    "# =====================================================================\n",
    "# image gethering\n",
    "def findBlogImgGethering(searchQuery, searchOption, page):\n",
    "    url = f'https://search.naver.com/search.naver?query={searchQuery}&sm=tab_pge&srchby=all&st={searchOption}&where=post&start={page}'\n",
    "    html = requests.get(url)\n",
    "    # 1차, blog URL 찾기\n",
    "    soup = BeautifulSoup(html.text, 'html.parser')\n",
    "    index = 0;\n",
    "\n",
    "    url_list = [];\n",
    "    for li_item in soup.find_all('li',{'class' : 'sh_blog_top'}):\n",
    "        child_item = li_item.find('a',{'class' : 'sh_blog_title'})\n",
    "        title = child_item.attrs['title']\n",
    "        href = child_item.attrs['href']\n",
    "\n",
    "        #url list 저장\n",
    "        url_list.append(href)\n",
    "\n",
    "        print(f'title : {title} , href : {href}')\n",
    "        print('----------------------------------')\n",
    "        \n",
    "    # url 파싱 및 예외처리\n",
    "    for url_item in url_list:\n",
    "        nickName = \"\";\n",
    "        postNumber = \"\";\n",
    "\n",
    "        if(url_item.find(\"blog.me\") > 0):\n",
    "            parsing = url_item;\n",
    "            parsing = parsing.replace(\"https://\",\"\")\n",
    "            nickName = parsing.split('.')[0]\n",
    "            postNumber = parsing.split('/')[1]\n",
    "            blogUrl = \"https://m.blog.naver.com/\" + nickName + \"?Redirect=Log&logNo=\" + postNumber\n",
    "\n",
    "        else:\n",
    "            blogUrl = url_item.replace(\"https://\", \"https://m.\");\n",
    "\n",
    "        nickName = blogUrl.split('/')[-1].split('?')[0]\n",
    "        postNumber = blogUrl.split('/')[-1].split('?')[1].split('=')[-1]\n",
    "\n",
    "        if nickName is \"\":\n",
    "            nickName = \"unknown\"\n",
    "        if postNumber is \"\":\n",
    "            postNumber = \"1\"\n",
    "            \n",
    "        print(\"------ digging more -------\")\n",
    "        print(\"nickName : \" , blogUrl.split('/')[-1].split('?')[0])\n",
    "        print(\"postNumber : \" , blogUrl.split('/')[-1].split('?')[1].split('=')[-1])\n",
    "        print(\"blogUrl : \" , blogUrl)        \n",
    "\n",
    "        #전체 목록 순회\n",
    "        blog_html = requests.get(blogUrl)\n",
    "        blog_soup = BeautifulSoup(blog_html.text, 'html.parser')\n",
    "        blog_image_class = blog_soup.find_all('div',{'class' : 'se-image'});\n",
    "\n",
    "        for div_obj in blog_image_class:\n",
    "            for idx, img_item in enumerate(div_obj.find_all('img')):\n",
    "                img_url = img_item.attrs['src'];\n",
    "\n",
    "                if(img_url.find(\"w80_blur\") > 0):\n",
    "                    img_url = img_url.replace(\"w80_blur\" , \"w800\")\n",
    "                isSaveSuccess = saveImage(False,index,img_url,nickName,postNumber)\n",
    "                if(isSaveSuccess):  \n",
    "                    index = index+1\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "title : 기가 막혔던 종각 맛집 , href : https://forurwinter.blog.me/221988900945\n",
      "----------------------------------\n",
      "title : 푸짐했던 종각 맛집 , href : https://blog.naver.com/celinicious?Redirect=Log&logNo=222006262433\n",
      "----------------------------------\n",
      "title : 짜릿했던 종각 맛집 , href : https://blog.naver.com/maeng_ee?Redirect=Log&logNo=221977654830\n",
      "----------------------------------\n",
      "title : 가성비 쩔었던 종각 맛집, 교대이층집 , href : https://blog.naver.com/el512?Redirect=Log&logNo=222008681533\n",
      "----------------------------------\n",
      "title : 끝장난 종각 맛집 , href : https://ssomerry.blog.me/221983614903\n",
      "----------------------------------\n",
      "title : 믿고갔던 종각 맛집 , href : https://blog.naver.com/porky0122?Redirect=Log&logNo=221991050525\n",
      "----------------------------------\n",
      "title : 0324 종각 고기집/콜키지프리 맛집 고메식당 , href : https://blog.naver.com/p_radn?Redirect=Log&logNo=221878088433\n",
      "----------------------------------\n",
      "title : 까리했던 종각 맛집 , href : https://blog.naver.com/ju_love1202?Redirect=Log&logNo=221952793333\n",
      "----------------------------------\n",
      "title : 흐뭇했던 종각 맛집 , href : https://blog.naver.com/hoon1033?Redirect=Log&logNo=221995568472\n",
      "----------------------------------\n",
      "title : 제대로 즐겼던 종각 맛집 , href : https://blog.naver.com/amy201427?Redirect=Log&logNo=221921204400\n",
      "----------------------------------\n",
      "------ digging more -------\n",
      "nickName :  forurwinter\n",
      "postNumber :  221988900945\n",
      "blogUrl :  https://m.blog.naver.com/forurwinter?Redirect=Log&logNo=221988900945\n",
      "img_url_final :  https://mblogthumb-phinf.pstatic.net/MjAyMDA2MDNfMjc1/MDAxNTkxMTc3NzMwOTcz._afrEDZevZpW09nyuuZ7mMcGLFBv4TVXF7lLe6mLoL8g.i1VeQRb65oJwFp7zewx64Yk5fuAgUBJrDcCpeipiaJQg.JPEG.forurwinter/1.JPG?type=w800\n",
      "input_arr type :  <class 'numpy.ndarray'>\n",
      "========pridiction========\n",
      "predictions class :  [[1]]\n",
      "predictions :  [[2053.01]]\n",
      "img_url_final :  https://mblogthumb-phinf.pstatic.net/MjAyMDA2MDNfMTAw/MDAxNTkxMTc3NzMwODcy.hjrCaQxEFRKUfcJIy6yirSlAdCNt07LADRe-Fq3_0isg.b7JYgbfBARee2uZ_j4QiLVrkPGCfSX-Pb6nYkmLa_Fcg.JPEG.forurwinter/2.JPG?type=w800\n",
      "input_arr type :  <class 'numpy.ndarray'>\n",
      "========pridiction========\n",
      "predictions class :  [[1]]\n",
      "predictions :  [[2436.7583]]\n",
      "img_url_final :  https://mblogthumb-phinf.pstatic.net/MjAyMDA2MDNfNDMg/MDAxNTkxMTc3NzMwOTQ4.---5RbkC4W5KNaJmesY7c6scJldC2RFH3pGqdOLpVA4g.mN0WKCx_AEPf6KJUAZGSLwMhG_NIuYCbBsgIttBTK5Ug.JPEG.forurwinter/3.JPG?type=w800\n",
      "input_arr type :  <class 'numpy.ndarray'>\n",
      "========pridiction========\n",
      "predictions class :  [[1]]\n",
      "predictions :  [[2871.8152]]\n",
      "img_url_final :  https://mblogthumb-phinf.pstatic.net/MjAyMDA2MDNfNTEg/MDAxNTkxMTc3NzMwOTI5.i6RTOiur5o8m3a_7LOi7A615UV7lBA7wCphWrtAS8Gog.8KYj69PSDqFa9xn219RSDrppnTEaeCJ6WqUzCilKIV4g.JPEG.forurwinter/4.JPG?type=w800\n",
      "input_arr type :  <class 'numpy.ndarray'>\n",
      "========pridiction========\n",
      "predictions class :  [[1]]\n",
      "predictions :  [[1928.0297]]\n",
      "img_url_final :  https://mblogthumb-phinf.pstatic.net/MjAyMDA2MDNfMjc0/MDAxNTkxMTc3NzMxNTQ5.tkk2aIYg_nu2NbSYeoB-oTmZtzakhgy1Gxl3xQjimrAg.t46OsQZXri8gdhU36f-0jpoyBHwdKhoK7u_Nk_DJrJ8g.JPEG.forurwinter/5.JPG?type=w800\n",
      "input_arr type :  <class 'numpy.ndarray'>\n",
      "========pridiction========\n",
      "predictions class :  [[1]]\n",
      "predictions :  [[2886.0027]]\n",
      "img_url_final :  https://mblogthumb-phinf.pstatic.net/MjAyMDA2MDNfMzcg/MDAxNTkxMTc3NzMxODcw.zwoNH4rtOiT0qRx6WB2qKhLJhyDe2yJiJRdsYNIel-cg.audkdibZbWWTSH-v3UdQgxZJlYZizBFwxLIP1qPQECMg.JPEG.forurwinter/6.JPG?type=w800\n",
      "input_arr type :  <class 'numpy.ndarray'>\n",
      "========pridiction========\n",
      "predictions class :  [[1]]\n",
      "predictions :  [[2124.1455]]\n",
      "img_url_final :  https://mblogthumb-phinf.pstatic.net/MjAyMDA2MDNfMTAw/MDAxNTkxMTc3NzMxODE1.m9J4YnwAEcKuotR2qLrmLoxS05MzwhNj5kepHOL42wUg.EkdR480RokKtCrPgfJl-SxQFGIaiHe39ZA_z90LJ3XAg.JPEG.forurwinter/7.JPG?type=w800\n",
      "input_arr type :  <class 'numpy.ndarray'>\n",
      "========pridiction========\n",
      "predictions class :  [[1]]\n",
      "predictions :  [[2594.8203]]\n",
      "img_url_final :  https://mblogthumb-phinf.pstatic.net/MjAyMDA2MDNfMjA1/MDAxNTkxMTc3NzMxOTMz.B2dVKkheWhv4KEEs88YwYil54b5GmDBybCLogBWOUMwg.L2UbI8ZVnbMjFYD3FPO7a6zPpE0_HdrAXHSb7mrMvPwg.JPEG.forurwinter/8.JPG?type=w800\n",
      "input_arr type :  <class 'numpy.ndarray'>\n",
      "========pridiction========\n",
      "predictions class :  [[1]]\n",
      "predictions :  [[2325.4812]]\n",
      "img_url_final :  https://mblogthumb-phinf.pstatic.net/MjAyMDA2MDNfMTc0/MDAxNTkxMTc3NzMxODAx.T3VdaNKBlLKNeYBGA69ovtauWIabpXaJK1IbX4CX7Q4g.7eQwWqPY5ifYsYmUSFgcDb4kTxn2Fl3wj3X3iwrkt84g.JPEG.forurwinter/9.JPG?type=w800\n",
      "input_arr type :  <class 'numpy.ndarray'>\n",
      "========pridiction========\n",
      "predictions class :  [[1]]\n",
      "predictions :  [[1588.197]]\n",
      "img_url_final :  https://mblogthumb-phinf.pstatic.net/MjAyMDA2MDNfMjg0/MDAxNTkxMTc3NzMxOTQ3.aWmpu6kYXyyZdu-FnmE-DLLRVTNSJNIIXohlfZK-yI4g.tW6sgoBZlfTEYf2KCiVM8LQLY4l4qJYSvHzhVoSr3lQg.JPEG.forurwinter/10.JPG?type=w800\n",
      "input_arr type :  <class 'numpy.ndarray'>\n",
      "========pridiction========\n",
      "predictions class :  [[1]]\n",
      "predictions :  [[2209.6536]]\n",
      "img_url_final :  https://mblogthumb-phinf.pstatic.net/MjAyMDA2MDNfNDYg/MDAxNTkxMTc3NzMyMDYw.-qmuQyzFm2kN_qXvt1fj3SgAwdk7kgibdwxU-uTxEi4g.FZwPBCCMrT46C_tcm7iAYjxRckhFIBHPZ-1rIGZ8vC4g.JPEG.forurwinter/11.JPG?type=w800\n",
      "input_arr type :  <class 'numpy.ndarray'>\n",
      "========pridiction========\n",
      "predictions class :  [[1]]\n",
      "predictions :  [[2782.1047]]\n",
      "img_url_final :  https://mblogthumb-phinf.pstatic.net/MjAyMDA2MDNfMTAx/MDAxNTkxMTc3NzMyNjIz.CV6wV3nLp7tsOFbTh9hjvIESGIfOpVq6C-A7mZkb-Ncg.MBcnQTGzwcw0oVUxX65Nq_yO7gaU5OuAW6GuKRFXsUcg.JPEG.forurwinter/12.JPG?type=w800\n",
      "input_arr type :  <class 'numpy.ndarray'>\n",
      "========pridiction========\n",
      "predictions class :  [[1]]\n",
      "predictions :  [[3057.474]]\n",
      "img_url_final :  https://mblogthumb-phinf.pstatic.net/MjAyMDA2MDNfNjEg/MDAxNTkxMTc3NzMyNTQ4.8XybkkKmyjPc2ibbo8ykqkAdvD_3asQmdDWxioJHYD0g.IzL1ffsCiqShYnXvjgdiu2TLRRRZ5sxWKycdx01TW0Ag.JPEG.forurwinter/13.JPG?type=w800\n",
      "input_arr type :  <class 'numpy.ndarray'>\n",
      "========pridiction========\n",
      "predictions class :  [[1]]\n",
      "predictions :  [[3042.8503]]\n",
      "img_url_final :  https://mblogthumb-phinf.pstatic.net/MjAyMDA2MDNfMiAg/MDAxNTkxMTc3NzMyNTMw.gfRjfq0fTaTppfZkq2CnGCrJrrDPNrtol_fB2KQIc4wg.kbHILDdNV_u28slVmzFjmw0vpSinCdqUpr4T19o3fA4g.JPEG.forurwinter/14.JPG?type=w800\n",
      "input_arr type :  <class 'numpy.ndarray'>\n",
      "========pridiction========\n",
      "predictions class :  [[1]]\n",
      "predictions :  [[2943.4817]]\n",
      "img_url_final :  https://mblogthumb-phinf.pstatic.net/MjAyMDA2MDNfMTE5/MDAxNTkxMTc3NzMyOTQ1.YG17Xa05PV2LSWCRL61I_pb8b7uAPz9xQZHxB7_5GrEg.IadrE9a7oleIWfV_mFs7cURE0tXSerWCP04DLiTNUxwg.JPEG.forurwinter/15.JPG?type=w800\n",
      "input_arr type :  <class 'numpy.ndarray'>\n",
      "========pridiction========\n",
      "predictions class :  [[1]]\n",
      "predictions :  [[2973.506]]\n",
      "img_url_final :  https://mblogthumb-phinf.pstatic.net/MjAyMDA2MDNfNjgg/MDAxNTkxMTc3NzMyNjgz.1m6GrGI-Ldnakg7xDt4sbVWyJ_hE8AQpcE9x-hqKfocg.CNo_RIQHaCEPud5Hvg3_MbxmBJwx-E8TzN90fcc7PLUg.JPEG.forurwinter/16.JPG?type=w800\n",
      "input_arr type :  <class 'numpy.ndarray'>\n",
      "========pridiction========\n",
      "predictions class :  [[1]]\n",
      "predictions :  [[2793.6409]]\n",
      "img_url_final :  https://mblogthumb-phinf.pstatic.net/MjAyMDA2MDNfMjY0/MDAxNTkxMTc3NzMzMzIy.G12Yy8-p48n1yugczF2f3JHjiDpULgUk666-bX6d5cQg.7S8RG2h6u2TzxfvDrzvdarOywS99JzoqI2n4gStlt54g.JPEG.forurwinter/17.JPG?type=w800\n",
      "input_arr type :  <class 'numpy.ndarray'>\n",
      "========pridiction========\n",
      "predictions class :  [[1]]\n",
      "predictions :  [[2746.207]]\n",
      "img_url_final :  https://mblogthumb-phinf.pstatic.net/MjAyMDA2MDNfMTMx/MDAxNTkxMTc3NzMzMDQ0.V0bRi4Ci_roV_mVZ5EScTAc5bzDl-m8vFDDSbdlx36Ug.4fJhxfG86NA2REe9JEeV4Hwzup_LVGcRYqCdca8ZNGkg.JPEG.forurwinter/18.JPG?type=w800\n",
      "input_arr type :  <class 'numpy.ndarray'>\n",
      "========pridiction========\n",
      "predictions class :  [[1]]\n",
      "predictions :  [[2585.7368]]\n",
      "img_url_final :  https://mblogthumb-phinf.pstatic.net/MjAyMDA2MDNfMjYg/MDAxNTkxMTc3NzMzMjIx.9qoFdV5QgGShQPeIqF4oL7vgIBNhNLS6XHuiUKrx1Zsg.hgbSuH9WKrH8_Yia0Rrfjr4kxbyDh6IXksZPxHl3DBUg.JPEG.forurwinter/19.JPG?type=w800\n",
      "input_arr type :  <class 'numpy.ndarray'>\n",
      "========pridiction========\n",
      "predictions class :  [[1]]\n",
      "predictions :  [[1987.7494]]\n",
      "img_url_final :  https://mblogthumb-phinf.pstatic.net/MjAyMDA2MDNfMTE1/MDAxNTkxMTc3NzMzMzI4.NcSdE7wenptQxOqT4SZCp_71Toyb5uMnOSu33ktSZYAg.gqpYROyg2jItjgVZseOQkEdPHsUavD4jD-34vyj4W_Mg.JPEG.forurwinter/20.JPG?type=w800\n",
      "input_arr type :  <class 'numpy.ndarray'>\n",
      "========pridiction========\n",
      "predictions class :  [[1]]\n",
      "predictions :  [[2308.8213]]\n",
      "img_url_final :  https://mblogthumb-phinf.pstatic.net/MjAyMDA2MDNfODMg/MDAxNTkxMTc3NzMzNDAz.RVIYfvEBccLlMwd8wtQ5IDhCd7nBVBGcRuUMKht4vU8g.rpKGfitXV-C6zXmpPoss8UrYR9tZA2EO6bmAWP3Ur-sg.JPEG.forurwinter/21.JPG?type=w800\n",
      "input_arr type :  <class 'numpy.ndarray'>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========pridiction========\n",
      "predictions class :  [[1]]\n",
      "predictions :  [[2041.5247]]\n",
      "img_url_final :  https://mblogthumb-phinf.pstatic.net/MjAyMDA2MDNfMTkw/MDAxNTkxMTc3NzMzOTUz.8Qb9xJrLh6iJPw2jY2M3UxAbx1PrY5AE32drET_J9yUg.f4-4A2aXdcbFRuKogDCRVM-NCljtkPVzN7IMTurIxYgg.JPEG.forurwinter/22.JPG?type=w800\n",
      "input_arr type :  <class 'numpy.ndarray'>\n",
      "========pridiction========\n",
      "predictions class :  [[1]]\n",
      "predictions :  [[1562.0582]]\n",
      "img_url_final :  https://mblogthumb-phinf.pstatic.net/MjAyMDA2MDNfMTc4/MDAxNTkxMTc3NzM0MDcw.yOmfTb4d1LfB7SEhQ16PR1ZG13DfDqOWZKd-5c096v4g.FXjgnkadmppJoluIleGC8thbXZpwQafvKz_ksZQl4s8g.JPEG.forurwinter/23.JPG?type=w800\n",
      "input_arr type :  <class 'numpy.ndarray'>\n",
      "========pridiction========\n",
      "predictions class :  [[1]]\n",
      "predictions :  [[2641.2659]]\n",
      "img_url_final :  https://mblogthumb-phinf.pstatic.net/MjAyMDA2MDNfMTk4/MDAxNTkxMTc3NzM0MTMy.bW1p4QDqfufeXfBjlTIn1LT9cibZFJEp9kRWMnDMkR8g.X7dv0oR70erncKFxFjT9ogjeyJOnDLcsfvBL0I8NmOEg.JPEG.forurwinter/24.JPG?type=w800\n",
      "input_arr type :  <class 'numpy.ndarray'>\n",
      "========pridiction========\n",
      "predictions class :  [[1]]\n",
      "predictions :  [[3092.0115]]\n",
      "img_url_final :  https://mblogthumb-phinf.pstatic.net/MjAyMDA2MDNfMTU3/MDAxNTkxMTc3NzMzODU2.ljlgXICd_OfX-OCT0sf9Wbi21MErwck-FcWPTCnARjgg.DMX5xIYB1URdGTuZZN5FJa6MrmYtI8qtGfu7RJBwitYg.JPEG.forurwinter/25.JPG?type=w800\n",
      "input_arr type :  <class 'numpy.ndarray'>\n",
      "========pridiction========\n",
      "predictions class :  [[1]]\n",
      "predictions :  [[3098.3455]]\n",
      "img_url_final :  https://mblogthumb-phinf.pstatic.net/MjAyMDA2MDNfMjM4/MDAxNTkxMTc3NzMzOTMy.fd-APeGV6VAsGbXlhVEE3k76aaseJ1mutQpXoLcjtv0g.899DWgcJ77vSOKmFAG3yAki5LkTjK2Mmf-xuFU62NRkg.JPEG.forurwinter/26.JPG?type=w800\n",
      "input_arr type :  <class 'numpy.ndarray'>\n",
      "========pridiction========\n",
      "predictions class :  [[1]]\n",
      "predictions :  [[2016.5065]]\n",
      "img_url_final :  https://mblogthumb-phinf.pstatic.net/MjAyMDA2MDNfMjc1/MDAxNTkxMTc3NzM0MDM2.GlTUcLLJagKTDTRLzfPs4dNSv8okRy6gR9hmpP2_ESYg.oKlj_xGoMWOmKlvCbglNbxALBC7xQ7CCRLFqZjaZymUg.JPEG.forurwinter/27.JPG?type=w800\n",
      "input_arr type :  <class 'numpy.ndarray'>\n",
      "========pridiction========\n",
      "predictions class :  [[1]]\n",
      "predictions :  [[2771.7166]]\n",
      "img_url_final :  https://mblogthumb-phinf.pstatic.net/MjAyMDA2MDNfOCAg/MDAxNTkxMTc3NzM0MzY4.H2R9w3TwlCBmnho_YLKeWle8V_kKHXf2XGtd-3Ifztog.I1bi8Hhx3WYS96BYxOt_-NBx5ulwqApX2kn1wWMwlwYg.JPEG.forurwinter/28.JPG?type=w800\n",
      "input_arr type :  <class 'numpy.ndarray'>\n",
      "========pridiction========\n",
      "predictions class :  [[1]]\n",
      "predictions :  [[2140.1245]]\n",
      "img_url_final :  https://mblogthumb-phinf.pstatic.net/MjAyMDA2MDNfMTcx/MDAxNTkxMTc3NzM0NDE4.XVNM5Uas_v7yWSegZXWSvpvAX0u8iTmasCKoQ_U4Yywg.j9Y9XMkR0bBdBFU2fVlxY5TLP6Co1Xknysh997st45cg.JPEG.forurwinter/29.JPG?type=w800\n",
      "input_arr type :  <class 'numpy.ndarray'>\n",
      "========pridiction========\n",
      "predictions class :  [[1]]\n",
      "predictions :  [[2105.8887]]\n",
      "img_url_final :  https://mblogthumb-phinf.pstatic.net/MjAyMDA2MDNfMjgz/MDAxNTkxMTc3NzM0NTIz.MyjqEv0GPZrZZqyyHrAbzIl6UyfBe8Lp_z3nGNsSXcEg.ORkRtL96RmCF1fjDBHP1DVBiSu6szxIDsyAr-dR_ecsg.JPEG.forurwinter/30.JPG?type=w800\n",
      "input_arr type :  <class 'numpy.ndarray'>\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-5e6e335595e1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mpage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mfindBlogImgGethering\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msearchQuery\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msearchOption\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mpage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-11-4380aa91b94f>\u001b[0m in \u001b[0;36mfindBlogImgGethering\u001b[0;34m(searchQuery, searchOption, page)\u001b[0m\n\u001b[1;32m    192\u001b[0m                 \u001b[0;32mif\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg_url\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"w80_blur\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    193\u001b[0m                     \u001b[0mimg_url\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimg_url\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"w80_blur\"\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0;34m\"w800\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 194\u001b[0;31m                 \u001b[0misSaveSuccess\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msaveImage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mimg_url\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnickName\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mpostNumber\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    195\u001b[0m                 \u001b[0;32mif\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0misSaveSuccess\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    196\u001b[0m                     \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-11-4380aa91b94f>\u001b[0m in \u001b[0;36msaveImage\u001b[0;34m(div_option, index, img_url, nickName, postNumber)\u001b[0m\n\u001b[1;32m    115\u001b[0m         \u001b[0;31m#분류\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m         \u001b[0;31m#{'advertise': 0, 'image': 1}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 117\u001b[0;31m         \u001b[0mmy_prediction\u001b[0m  \u001b[0;34m=\u001b[0m \u001b[0mimageClassification\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimgPath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    118\u001b[0m         \u001b[0;31m#my_prediction  = teachableMachinePrediction(imgPath);\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m \u001b[0;31m#         print(\"prediction : \", my_prediction[0]);\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-11-4380aa91b94f>\u001b[0m in \u001b[0;36mimageClassification\u001b[0;34m(image_path)\u001b[0m\n\u001b[1;32m     59\u001b[0m     \u001b[0minput_arr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0minput_arr\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Convert single image to a batch.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m     \u001b[0mpredictions_class\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_classes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_arr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     62\u001b[0m     \u001b[0mpredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_arr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/tensorflow/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/sequential.py\u001b[0m in \u001b[0;36mpredict_classes\u001b[0;34m(self, x, batch_size, verbose)\u001b[0m\n\u001b[1;32m    336\u001b[0m         \u001b[0mA\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0marray\u001b[0m \u001b[0mof\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mpredictions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    337\u001b[0m     \"\"\"\n\u001b[0;32m--> 338\u001b[0;31m     \u001b[0mproba\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    339\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mproba\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    340\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mproba\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/tensorflow/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, x, batch_size, verbose, steps, callbacks, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1011\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1012\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1013\u001b[0;31m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[1;32m   1014\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1015\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mreset_metrics\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/tensorflow/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, model, x, batch_size, verbose, steps, callbacks, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    496\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mModeKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPREDICT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    497\u001b[0m         \u001b[0msteps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_queue_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 498\u001b[0;31m         workers=workers, use_multiprocessing=use_multiprocessing, **kwargs)\n\u001b[0m\u001b[1;32m    499\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    500\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/tensorflow/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2.py\u001b[0m in \u001b[0;36m_model_iteration\u001b[0;34m(self, model, mode, x, y, batch_size, verbose, sample_weight, steps, callbacks, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    473\u001b[0m               \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    474\u001b[0m               \u001b[0mtraining_context\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtraining_context\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 475\u001b[0;31m               total_epochs=1)\n\u001b[0m\u001b[1;32m    476\u001b[0m           \u001b[0mcbks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_logs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch_logs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    477\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/tensorflow/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2.py\u001b[0m in \u001b[0;36mrun_one_epoch\u001b[0;34m(model, iterator, execution_function, dataset_size, batch_size, strategy, steps_per_epoch, num_samples, mode, training_context, total_epochs)\u001b[0m\n\u001b[1;32m    126\u001b[0m         step=step, mode=mode, size=current_batch_size) as batch_logs:\n\u001b[1;32m    127\u001b[0m       \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 128\u001b[0;31m         \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexecution_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    129\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mStopIteration\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOutOfRangeError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m         \u001b[0;31m# TODO(kaftan): File bug about tf function and errors.OutOfRangeError?\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/tensorflow/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2_utils.py\u001b[0m in \u001b[0;36mexecution_function\u001b[0;34m(input_fn)\u001b[0m\n\u001b[1;32m     96\u001b[0m     \u001b[0;31m# `numpy` translates Tensors to values in Eager mode.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m     return nest.map_structure(_non_none_constant_value,\n\u001b[0;32m---> 98\u001b[0;31m                               distributed_function(input_fn))\n\u001b[0m\u001b[1;32m     99\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mexecution_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/tensorflow/lib/python3.7/site-packages/tensorflow_core/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    566\u001b[0m         \u001b[0mxla_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mExit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    567\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 568\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    569\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    570\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtracing_count\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/tensorflow/lib/python3.7/site-packages/tensorflow_core/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    604\u001b[0m       \u001b[0;31m# In this case we have not created variables on the first call. So we can\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    605\u001b[0m       \u001b[0;31m# run the first trace but we should fail if variables are created.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 606\u001b[0;31m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    607\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_created_variables\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    608\u001b[0m         raise ValueError(\"Creating variables on a non-first call to a function\"\n",
      "\u001b[0;32m~/opt/anaconda3/envs/tensorflow/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2361\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2362\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2363\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2364\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2365\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/tensorflow/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   1609\u001b[0m          if isinstance(t, (ops.Tensor,\n\u001b[1;32m   1610\u001b[0m                            resource_variable_ops.BaseResourceVariable))),\n\u001b[0;32m-> 1611\u001b[0;31m         self.captured_inputs)\n\u001b[0m\u001b[1;32m   1612\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1613\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/tensorflow/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1690\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1691\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1692\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1693\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1694\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/tensorflow/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    543\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    544\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"executor_type\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexecutor_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"config_proto\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 545\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    546\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    547\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[0;32m~/opt/anaconda3/envs/tensorflow/lib/python3.7/site-packages/tensorflow_core/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tensorflow.TFE_Py_Execute(ctx._handle, device_name,\n\u001b[1;32m     60\u001b[0m                                                \u001b[0mop_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m                                                num_outputs)\n\u001b[0m\u001b[1;32m     62\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "searchQuery = \"종각 맛집\"\n",
    "searchOption = 'sim'  #sim or date  \n",
    "page = 1\n",
    "\n",
    "findBlogImgGethering(searchQuery,searchOption,page)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
